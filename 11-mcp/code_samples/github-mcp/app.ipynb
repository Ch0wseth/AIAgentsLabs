{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74177f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb20f4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_service_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")\n",
    "search_api_key = os.getenv(\"AZURE_SEARCH_API_KEY\")\n",
    "print(\"search_service_endpoint\", search_service_endpoint)\n",
    "print(\"search_api_key\", search_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31961ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "import chainlit as cl\n",
    "from mcp import ClientSession\n",
    "\n",
    "from semantic_kernel.kernel import Kernel\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "\n",
    "from semantic_kernel.functions import KernelFunction, kernel_function\n",
    "from semantic_kernel.contents import ChatHistory, AuthorRole, ChatMessageContent\n",
    "from semantic_kernel.connectors.ai import FunctionChoiceBehavior\n",
    "from semantic_kernel.contents.function_call_content import FunctionCallContent\n",
    "from semantic_kernel.contents.function_result_content import FunctionResultContent\n",
    "from semantic_kernel.connectors.mcp import MCPStdioPlugin\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.agents import ChatCompletionAgent, ChatHistoryAgentThread, AgentGroupChat\n",
    "from semantic_kernel.agents.strategies import (\n",
    "    SequentialSelectionStrategy,\n",
    "    DefaultTerminationStrategy\n",
    ")\n",
    "\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import SearchIndex, SimpleField, SearchFieldDataType, SearchableField\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Example Weather Plugin (Tool)\n",
    "\n",
    "        \n",
    "\n",
    "class RAGPlugin:\n",
    "    def __init__(self, search_client):\n",
    "        self.search_client = search_client\n",
    "\n",
    "    @kernel_function(name=\"search_events\", description=\"Searches for relevant events based on a query\")\n",
    "    def search_events(self, query: str) -> str:\n",
    "        \"\"\"Retrieves relevant events from Azure Search based on the query.\"\"\"\n",
    "        try:\n",
    "            results = self.search_client.search(query, top=5)\n",
    "            context_strings = []\n",
    "            for result in results:\n",
    "                if 'content' in result:\n",
    "                    context_strings.append(f\"Event: {result['content']}\")\n",
    "\n",
    "            if context_strings:\n",
    "                return \"\\n\\n\".join(context_strings)\n",
    "            else:\n",
    "                return \"No relevant events found.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error searching for events: {str(e)}\"\n",
    "\n",
    "\n",
    "# Initialize Azure AI Search with persistent storage\n",
    "search_service_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")\n",
    "search_api_key = os.getenv(\"AZURE_SEARCH_API_KEY\")\n",
    "index_name = \"event-descriptions\"\n",
    "\n",
    "search_client = SearchClient(\n",
    "    endpoint=search_service_endpoint,\n",
    "    index_name=index_name,\n",
    "    credential=AzureKeyCredential(search_api_key)\n",
    ")\n",
    "\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=search_service_endpoint,\n",
    "    credential=AzureKeyCredential(search_api_key)\n",
    ")\n",
    "\n",
    "# Define the index schema\n",
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "    SearchableField(name=\"content\", type=SearchFieldDataType.String)\n",
    "]\n",
    "\n",
    "index = SearchIndex(name=index_name, fields=fields)\n",
    "\n",
    "# Check if index already exists if not, create it\n",
    "try:\n",
    "    existing_index = index_client.get_index(index_name)\n",
    "    print(f\"Index '{index_name}' already exists, using the existing index.\")\n",
    "except Exception as e:\n",
    "    # Create the index if it doesn't exist\n",
    "    print(f\"Creating new index '{index_name}'...\")\n",
    "    index_client.create_index(index)\n",
    "\n",
    "# Always read event descriptions from markdown file\n",
    "with open(\"event-descriptions.md\", \"r\") as f:\n",
    "    markdown_content = f.read()\n",
    "\n",
    "# Split the markdown content into individual event descriptions\n",
    "event_descriptions = markdown_content.split(\"---\")  # You can change the delimiter\n",
    "\n",
    "# Create documents for Azure Search\n",
    "documents = []\n",
    "for i, description in enumerate(event_descriptions):\n",
    "    description = description.strip()  # Remove leading/trailing whitespace\n",
    "    if description:  # Avoid empty descriptions\n",
    "        documents.append({\"id\": str(i + 1), \"content\": description})\n",
    "\n",
    "# Add documents to the index (only if we have documents)\n",
    "if documents:\n",
    "    # Delete existing documents first to avoid duplicates\n",
    "    try:\n",
    "        search_client.delete_documents(documents=[{\"id\": doc[\"id\"]} for doc in documents])\n",
    "        print(\"Cleared existing documents\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Failed to clear existing documents: {str(e)}\")\n",
    "    \n",
    "    # Upload new documents\n",
    "    search_client.upload_documents(documents)\n",
    "    print(f\"Uploaded {len(documents)} documents to index\")\n",
    "\n",
    "def flatten(xss):\n",
    "    return [x for xs in xss for x in xs]\n",
    "\n",
    "\n",
    "@cl.on_mcp_connect\n",
    "async def on_mcp(connection, session: ClientSession):\n",
    "    result = await session.list_tools()\n",
    "    tools = [{\n",
    "        \"name\": t.name,\n",
    "        \"description\": t.description,\n",
    "        \"input_schema\": t.inputSchema,\n",
    "    } for t in result.tools]\n",
    "\n",
    "    mcp_tools = cl.user_session.get(\"mcp_tools\", {})\n",
    "    mcp_tools[connection.name] = tools\n",
    "    cl.user_session.set(\"mcp_tools\", mcp_tools)\n",
    "\n",
    "\n",
    "@cl.step(type=\"tool\")\n",
    "async def call_tool(tool_use):\n",
    "    tool_name = tool_use.name\n",
    "    tool_input = tool_use.input\n",
    "\n",
    "    current_step = cl.context.current_step\n",
    "    current_step.name = tool_name\n",
    "\n",
    "    # Identify which mcp is used\n",
    "    mcp_tools = cl.user_session.get(\"mcp_tools\", {})\n",
    "    mcp_name = None\n",
    "\n",
    "    for connection_name, tools in mcp_tools.items():\n",
    "        if any(tool.get(\"name\") == tool_name for tool in tools):\n",
    "            mcp_name = connection_name\n",
    "            break\n",
    "\n",
    "    if not mcp_name:\n",
    "        current_step.output = json.dumps(\n",
    "            {\"error\": f\"Tool {tool_name} not found in any MCP connection\"})\n",
    "        return current_step.output\n",
    "\n",
    "    mcp_session, _ = cl.context.session.mcp_sessions.get(mcp_name)\n",
    "\n",
    "    if not mcp_session:\n",
    "        current_step.output = json.dumps(\n",
    "            {\"error\": f\"MCP {mcp_name} not found in any MCP connection\"})\n",
    "        return current_step.output\n",
    "\n",
    "    try:\n",
    "        current_step.output = await mcp_session.call_tool(tool_name, tool_input)\n",
    "    except Exception as e:\n",
    "        current_step.output = json.dumps({\"error\": str(e)})\n",
    "\n",
    "    return current_step.output\n",
    "\n",
    "\n",
    "@cl.on_chat_start\n",
    "async def on_chat_start():\n",
    " \n",
    "    # Create kernel\n",
    "    kernel = Kernel()\n",
    "\n",
    "    # Define service ID\n",
    "    service_id = \"agent\"\n",
    "\n",
    "    # Create and add chat completion service\n",
    "    # chat_completion_service = OpenAIChatCompletion(\n",
    "    #     ai_model_id=\"gpt-4o-mini\",\n",
    "    #     async_client=client,\n",
    "    #     service_id=service_id\n",
    "    # )\n",
    "\n",
    "    sk_filter = cl.SemanticKernelFilter(kernel=kernel)\n",
    "\n",
    "    kernel.add_service(AzureChatCompletion(service_id=service_id))\n",
    "    settings = kernel.get_prompt_execution_settings_from_service_id(\n",
    "        service_id=service_id)\n",
    "    settings.function_choice_behavior = FunctionChoiceBehavior.Auto()\n",
    "\n",
    " \n",
    "\n",
    "    # Create a properly instantiated RAGPlugin\n",
    "    rag_plugin = RAGPlugin(search_client)\n",
    "\n",
    "    # Add to kernel\n",
    "    kernel.add_plugin(rag_plugin, plugin_name=\"RAG\")\n",
    "\n",
    "    # Store in session\n",
    "    cl.user_session.set(\"rag_plugin\", rag_plugin)\n",
    "\n",
    "    # Add GitHub MCP plugin\n",
    "    try:\n",
    "        # Create GitHub MCP plugin using MCPStdioPlugin\n",
    "        github_plugin = MCPStdioPlugin(\n",
    "            name=\"Github\",\n",
    "            description=\"Github Plugin\",\n",
    "            command=\"npx\",\n",
    "            args=[\"-y\", \"@modelcontextprotocol/server-github\"]\n",
    "        )\n",
    "\n",
    "        # Connect to the GitHub MCP server\n",
    "        await github_plugin.connect()\n",
    "\n",
    "        # Add the plugin to the kernel\n",
    "        kernel.add_plugin(github_plugin)\n",
    "\n",
    "        # Store the plugin in user session for cleanup later\n",
    "        cl.user_session.set(\"github_plugin\", github_plugin)\n",
    "\n",
    "        print(\"GitHub plugin added successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error adding GitHub plugin: {str(e)}\")\n",
    "\n",
    "    GITHUB_INSTRUCTIONS = \"\"\"\n",
    "You are an expert on GitHub repositories. When answering questions, you **must** use the provided GitHub username to find specific information about that user's repositories, including:\n",
    "\n",
    "*   Who created the repositories\n",
    "*   The programming languages used\n",
    "*   Information found in files and README.md files within those repositories\n",
    "*   Provide links to each repository referenfced in your answers\n",
    "\n",
    "**Important:** Never perform general searches for repositories. Always use the given GitHub username to find the relevant information. If a GitHub username is not provided, state that you need a username to proceed.\n",
    "    \"\"\"\n",
    "\n",
    "    HACKATHON_AGENT = \"\"\"\n",
    "You are an AI Agent Hackathon Strategist specializing in recommending winning project ideas.\n",
    "\n",
    "Your task:\n",
    "1. Analyze the GitHub activity of users to understand their technical skills\n",
    "2. Suggest creative AI Agent projects tailored to their expertise. \n",
    "3. Focus on projects that align with Microsoft's AI Agent Hackathon prize categories\n",
    "\n",
    "When making recommendations:\n",
    "- Base your ideas strictly on the user's GitHub repositories, languages, and tools\n",
    "- Give suggestions on tools, languaghes and framweworks to use to build it. \n",
    "- Provide detailed project descriptions including architecture and implementation approach\n",
    "- Explain why the project has potential to win in specific prize categories\n",
    "- Highlight technical feasibility given the user's demonstrated skills by referencing the specific repositories or languages used.\n",
    "\n",
    "Formatting your response:\n",
    "- Provide a clear and structured response that includes:\n",
    "    - Suggested Project Name\n",
    "    - Project Description \n",
    "    - Potential languages and tools to use\n",
    "    - Link to each relevant GitHub repository you based your recommendation on\n",
    "\n",
    "Hackathon prize categories:\n",
    "- Best Overall Agent ($20,000)\n",
    "- Best Agent in Python ($5,000)\n",
    "- Best Agent in C# ($5,000)\n",
    "- Best Agent in Java ($5,000)\n",
    "- Best Agent in JavaScript/TypeScript ($5,000)\n",
    "- Best Copilot Agent using Microsoft Copilot Studio or Microsoft 365 Agents SDK ($5,000)\n",
    "- Best Azure AI Agent Service Usage ($5,000)\n",
    "        \n",
    "\"\"\"\n",
    "\n",
    "    EVENTS_AGENT = \"\"\"\n",
    "You are an Event Recommendation Agent specializing in suggesting relevant tech events.\n",
    "\n",
    "Your task:\n",
    "1. Review the project idea recommended by the Hackathon Agent\n",
    "2. Use the search_events function to find relevant events based on the technologies mentioned.\n",
    "3. NEVER suggest and event that the where there is not a relevant technology that the user has used.\n",
    "3. ONLY recommend events that were returned by the search_events functionf\n",
    "\n",
    "When making recommendations:\n",
    "- IMPORTANT: You must first call the search_events function with appropriate technology keywords from the project\n",
    "- Only recommend events that were explicitly returned by the search_events function\n",
    "- Do not make up or suggest events that weren't in the search results\n",
    "- Construct search queries using specific technologies mentioned (e.g., \"Python AI workshop\" or \"JavaScript hackathon\")\n",
    "- Try multiple search queries if needed to find the most relevant events\n",
    "\n",
    "\n",
    "For each recommended event:\n",
    "- Only include events found in the search_events results\n",
    "- Explain the direct connection between the event and the specific project requirements\n",
    "- Highlight relevant workshops, sessions, or networking opportunities\n",
    "\n",
    "Formatting your response:\n",
    "- Start with \"Based on the hackathon project idea, here are relevant events that I found:\"\n",
    "- Only list events that were returned by the search_events function\n",
    "- For each event, include the exact event details as returned by search_events\n",
    "- Explain specifically how each event relates to the project technologies\n",
    "\n",
    "If no relevant events are found, acknowledge this and suggest trying different search terms instead of making up events.\n",
    "\"\"\"\n",
    "\n",
    "    github_agent = ChatCompletionAgent(\n",
    "        service=AzureChatCompletion(),\n",
    "        name=\"GithubAgent\",\n",
    "        instructions=GITHUB_INSTRUCTIONS,\n",
    "        plugins=[github_plugin]\n",
    "    )\n",
    "\n",
    "    hackathon_agent = ChatCompletionAgent(\n",
    "        service=AzureChatCompletion(),\n",
    "        name=\"HackathonAgent\",\n",
    "        instructions=HACKATHON_AGENT\n",
    "    )\n",
    "\n",
    "    events_agent = ChatCompletionAgent(\n",
    "        service=AzureChatCompletion(),\n",
    "        name=\"EventsAgent\",\n",
    "        instructions=EVENTS_AGENT,\n",
    "        plugins=[rag_plugin]  # Add the plugin here\n",
    "    )\n",
    "\n",
    "    # Create the agent group chat\n",
    "    agent_group_chat = AgentGroupChat(\n",
    "        agents=[github_agent, hackathon_agent, events_agent],\n",
    "        selection_strategy=SequentialSelectionStrategy(\n",
    "            initial_agent=github_agent),\n",
    "        termination_strategy=DefaultTerminationStrategy(maximum_iterations=3)\n",
    "    )\n",
    "\n",
    "    # Create a new chat history\n",
    "    chat_history = ChatHistory()\n",
    "\n",
    "    # Store in user session\n",
    "    cl.user_session.set(\"kernel\", kernel)\n",
    "    cl.user_session.set(\"settings\", settings)  # Store settings in session\n",
    "    cl.user_session.set(\"chat_completion_service\", AzureChatCompletion())\n",
    "    cl.user_session.set(\"chat_history\", chat_history)\n",
    "    cl.user_session.set(\"mcp_tools\", {})\n",
    "    # Store the agent group chat\n",
    "    cl.user_session.set(\"agent_group_chat\", agent_group_chat)\n",
    "\n",
    "\n",
    "# Add a cleanup handler for when the session ends\n",
    "@cl.on_chat_end\n",
    "async def on_chat_end():\n",
    "    # Get the GitHub plugin if it exists\n",
    "    github_plugin = cl.user_session.get(\"github_plugin\")\n",
    "    if github_plugin:\n",
    "        try:\n",
    "            await github_plugin.close()\n",
    "            print(\"GitHub plugin closed successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error closing GitHub plugin: {str(e)}\")\n",
    "\n",
    "\n",
    "@cl.on_message\n",
    "async def on_message(message: cl.Message):\n",
    "    kernel = cl.user_session.get(\"kernel\")\n",
    "    chat_completion_service = cl.user_session.get(\"chat_completion_service\")\n",
    "    chat_history = cl.user_session.get(\"chat_history\")\n",
    "    settings = cl.user_session.get(\"settings\")\n",
    "    agent_group_chat = cl.user_session.get(\"agent_group_chat\")\n",
    "    sk_filter = cl.SemanticKernelFilter(kernel=kernel)\n",
    "\n",
    "\n",
    "    # Check if the message is requesting a hackathon project recommendation\n",
    "    user_input = message.content.lower()\n",
    "    if \"recommend\" and \"github\" in user_input:\n",
    "        sk_filter = cl.SemanticKernelFilter(kernel=kernel)\n",
    "\n",
    "        # Add user message to chat history\n",
    "        chat_history.add_user_message(message.content)\n",
    "\n",
    "        # Add user message to the agent group chat's channel\n",
    "        await agent_group_chat.add_chat_message(message.content)\n",
    "\n",
    "        # Create message for response stream - USE ONLY ONE MESSAGE OBJECT\n",
    "        answer = cl.Message(content=\"Processing your request using GitHub, Hackathon and Events agents...\\n\\n\")\n",
    "        await answer.send()\n",
    "\n",
    "        agent_responses = []\n",
    "        async for content in agent_group_chat.invoke():\n",
    "            agent_name = content.name or \"Agent\"\n",
    "            response = f\"**{agent_name}**: {content.content}\"\n",
    "            agent_responses.append(response)\n",
    "            await answer.stream_token(f\"{response}\\n\\n\")\n",
    "\n",
    "        # Add the full agent responses to chat history\n",
    "        full_response = \"\\n\\n\".join(agent_responses)\n",
    "        chat_history.add_assistant_message(full_response)\n",
    "\n",
    "        # Update the message with all responses\n",
    "        answer.content = full_response\n",
    "        await answer.update()\n",
    "    else:\n",
    "        # Regular processing for other messages\n",
    "        # Add user message to history\n",
    "        chat_history.add_user_message(message.content)\n",
    "\n",
    "        # Create a Chainlit message for the response stream\n",
    "        answer = cl.Message(content=\"\")\n",
    "\n",
    "        async for msg in chat_completion_service.get_streaming_chat_message_content(\n",
    "            chat_history=chat_history,\n",
    "            user_input=message.content,\n",
    "            settings=settings,\n",
    "            kernel=kernel,\n",
    "        ):\n",
    "            if msg.content:\n",
    "                await answer.stream_token(msg.content)\n",
    "            # Handle function calls if they occur\n",
    "            if isinstance(msg, FunctionCallContent):\n",
    "                function_name = msg.function_name\n",
    "                function_arguments = msg.arguments\n",
    "                await answer.stream_token(f\"\\n\\nCalling function: {function_name} with arguments: {function_arguments}\\n\\n\")\n",
    "            # Handle function results\n",
    "            if isinstance(msg, FunctionResultContent):\n",
    "                await answer.stream_token(f\"Function result: {msg.content}\\n\\n\")\n",
    "\n",
    "        # Add the full assistant response to history\n",
    "        chat_history.add_assistant_message(answer.content)\n",
    "\n",
    "        # Send the final message\n",
    "        await answer.send()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
